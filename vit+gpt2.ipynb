{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-14T02:31:09.703994Z",
     "iopub.status.busy": "2024-04-14T02:31:09.703091Z",
     "iopub.status.idle": "2024-04-14T02:31:34.176781Z",
     "shell.execute_reply": "2024-04-14T02:31:34.175282Z",
     "shell.execute_reply.started": "2024-04-14T02:31:09.703958Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "!pip install rouge_score -q\n",
    "!pip install deep-phonemizer -q\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T02:31:34.178986Z",
     "iopub.status.busy": "2024-04-14T02:31:34.178629Z",
     "iopub.status.idle": "2024-04-14T02:31:42.008590Z",
     "shell.execute_reply": "2024-04-14T02:31:42.007426Z",
     "shell.execute_reply.started": "2024-04-14T02:31:34.178953Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import io, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from transformers import Seq2SeqTrainer ,Seq2SeqTrainingArguments\n",
    "from transformers import VisionEncoderDecoderModel , ViTFeatureExtractor\n",
    "from transformers import AutoTokenizer ,  GPT2Config , default_data_collator\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T02:31:42.010796Z",
     "iopub.status.busy": "2024-04-14T02:31:42.010119Z",
     "iopub.status.idle": "2024-04-14T02:31:42.017807Z",
     "shell.execute_reply": "2024-04-14T02:31:42.016551Z",
     "shell.execute_reply.started": "2024-04-14T02:31:42.010763Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "class config : \n",
    "    ENCODER = \"google/vit-base-patch16-224\"\n",
    "    DECODER = \"gpt2\"\n",
    "    TRAIN_BATCH_SIZE = 8\n",
    "    VAL_BATCH_SIZE = 8\n",
    "    VAL_EPOCHS = 1\n",
    "    LR = 5e-5\n",
    "    SEED = 42\n",
    "    MAX_LEN = 128\n",
    "    SUMMARY_LEN = 20\n",
    "    WEIGHT_DECAY = 0.01\n",
    "    MEAN = (0.485, 0.456, 0.406)\n",
    "    STD = (0.229, 0.224, 0.225)\n",
    "    TRAIN_PCT = 0.95\n",
    "    NUM_WORKERS = mp.cpu_count()\n",
    "    EPOCHS = 3\n",
    "    IMG_SIZE = (224,224)\n",
    "    LABEL_MASK = -100\n",
    "    TOP_K = 1000\n",
    "    TOP_P = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T02:31:42.021134Z",
     "iopub.status.busy": "2024-04-14T02:31:42.020494Z",
     "iopub.status.idle": "2024-04-14T02:31:42.029893Z",
     "shell.execute_reply": "2024-04-14T02:31:42.028860Z",
     "shell.execute_reply.started": "2024-04-14T02:31:42.021100Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n",
    "    outputs = [self.bos_token_id] + token_ids_0 + [self.eos_token_id]\n",
    "    return outputs\n",
    "AutoTokenizer.build_inputs_with_special_tokens = build_inputs_with_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T02:31:42.032322Z",
     "iopub.status.busy": "2024-04-14T02:31:42.031412Z",
     "iopub.status.idle": "2024-04-14T02:31:42.509405Z",
     "shell.execute_reply": "2024-04-14T02:31:42.508149Z",
     "shell.execute_reply.started": "2024-04-14T02:31:42.032292Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rouge = datasets.load_metric(\"rouge\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    # all unnecessary tokens are removed\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
    "\n",
    "    return {\n",
    "        \"rouge2_precision\": round(rouge_output.precision, 4),\n",
    "        \"rouge2_recall\": round(rouge_output.recall, 4),\n",
    "        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T02:31:42.511531Z",
     "iopub.status.busy": "2024-04-14T02:31:42.510872Z",
     "iopub.status.idle": "2024-04-14T02:31:42.805205Z",
     "shell.execute_reply": "2024-04-14T02:31:42.804026Z",
     "shell.execute_reply.started": "2024-04-14T02:31:42.511494Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "feature_extractor = ViTFeatureExtractor.from_pretrained(config.ENCODER)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.DECODER)\n",
    "tokenizer.pad_token = tokenizer.unk_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T02:31:42.807265Z",
     "iopub.status.busy": "2024-04-14T02:31:42.806581Z",
     "iopub.status.idle": "2024-04-14T02:31:42.887025Z",
     "shell.execute_reply": "2024-04-14T02:31:42.885810Z",
     "shell.execute_reply.started": "2024-04-14T02:31:42.807225Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(config.IMG_SIZE), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=0.5, \n",
    "            std=0.5\n",
    "        )\n",
    "   ]\n",
    ")\n",
    "df=  pd.read_csv(\"/kaggle/input/flickr8k/captions.txt\")\n",
    "train_df , val_df = train_test_split(df , test_size = 0.2)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T02:31:42.888889Z",
     "iopub.status.busy": "2024-04-14T02:31:42.888447Z",
     "iopub.status.idle": "2024-04-14T02:31:42.901383Z",
     "shell.execute_reply": "2024-04-14T02:31:42.900268Z",
     "shell.execute_reply.started": "2024-04-14T02:31:42.888852Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, df,root_dir,tokenizer,feature_extractor, transform = None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.root_dir = root_dir\n",
    "        self.tokenizer= tokenizer\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.max_length = 50\n",
    "    def __len__(self,):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self,idx):\n",
    "        caption = self.df.caption.iloc[idx]\n",
    "        image = self.df.image.iloc[idx]\n",
    "        img_path = os.path.join(self.root_dir , image)\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img= self.transform(img)\n",
    "            \n",
    "        pixel_values = self.feature_extractor(img, return_tensors=\"pt\").pixel_values\n",
    "        captions = self.tokenizer(caption,\n",
    "                                 padding='max_length',\n",
    "                                 max_length=self.max_length).input_ids\n",
    "        captions = [caption if caption != self.tokenizer.pad_token_id else -100 for caption in captions]\n",
    "        encoding = {\"pixel_values\": pixel_values.squeeze(), \"labels\": torch.tensor(captions)}\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T02:31:42.903934Z",
     "iopub.status.busy": "2024-04-14T02:31:42.903256Z",
     "iopub.status.idle": "2024-04-14T02:31:42.916844Z",
     "shell.execute_reply": "2024-04-14T02:31:42.915596Z",
     "shell.execute_reply.started": "2024-04-14T02:31:42.903895Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = ImgDataset(train_df, root_dir = \"/kaggle/input/flickr8k/Images\",tokenizer=tokenizer,feature_extractor = feature_extractor ,transform = transforms)\n",
    "val_dataset = ImgDataset(val_df , root_dir = \"/kaggle/input/flickr8k/Images\",tokenizer=tokenizer,feature_extractor = feature_extractor , transform  = transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T02:31:42.919160Z",
     "iopub.status.busy": "2024-04-14T02:31:42.918086Z",
     "iopub.status.idle": "2024-04-14T02:31:44.435686Z",
     "shell.execute_reply": "2024-04-14T02:31:44.434554Z",
     "shell.execute_reply.started": "2024-04-14T02:31:42.919128Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(config.ENCODER, config.DECODER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T02:31:44.437739Z",
     "iopub.status.busy": "2024-04-14T02:31:44.437264Z",
     "iopub.status.idle": "2024-04-14T02:31:44.445574Z",
     "shell.execute_reply": "2024-04-14T02:31:44.444255Z",
     "shell.execute_reply.started": "2024-04-14T02:31:44.437679Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "# make sure vocab size is set correctly\n",
    "model.config.vocab_size = model.config.decoder.vocab_size\n",
    "# set beam search parameters\n",
    "model.config.eos_token_id = tokenizer.sep_token_id\n",
    "model.config.decoder_start_token_id = tokenizer.bos_token_id\n",
    "model.config.max_length = 128\n",
    "model.config.early_stopping = True\n",
    "model.config.no_repeat_ngram_size = 3\n",
    "model.config.length_penalty = 2.0\n",
    "model.config.num_beams = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T02:31:44.448516Z",
     "iopub.status.busy": "2024-04-14T02:31:44.447407Z",
     "iopub.status.idle": "2024-04-14T02:31:44.471989Z",
     "shell.execute_reply": "2024-04-14T02:31:44.470639Z",
     "shell.execute_reply.started": "2024-04-14T02:31:44.448479Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='VIT_large_gpt2',\n",
    "    per_device_train_batch_size=config.TRAIN_BATCH_SIZE,\n",
    "    per_device_eval_batch_size=config.VAL_BATCH_SIZE,\n",
    "    predict_with_generate=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    logging_steps=1024,  \n",
    "    save_steps=2048, \n",
    "    warmup_steps=1024,  \n",
    "    learning_rate = 5e-5,\n",
    "    #max_steps=1500, # delete for full training\n",
    "    num_train_epochs = config.EPOCHS, #TRAIN_EPOCHS\n",
    "    overwrite_output_dir=True,\n",
    "    save_total_limit=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T02:31:44.476216Z",
     "iopub.status.busy": "2024-04-14T02:31:44.475401Z",
     "iopub.status.idle": "2024-04-14T02:31:46.403478Z",
     "shell.execute_reply": "2024-04-14T02:31:46.400773Z",
     "shell.execute_reply.started": "2024-04-14T02:31:44.476180Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    tokenizer=feature_extractor,\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=default_data_collator,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 623289,
     "sourceId": 1111676,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30684,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
